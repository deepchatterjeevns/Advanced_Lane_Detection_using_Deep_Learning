{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Detection\n",
    "\n",
    "## (using Deep Learning)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Import TensorFlow and Keras libraries\n",
    "\n",
    "We will start by importing all the necessary libraries for Keras and TensorFlow. Apart from these libraries, we will also import some other libraries such as NumPy, Glob, cv2, csv, and MatPlotLib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import GPUtil as GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU information\n",
    "\n",
    "Here, we will print some information related to GPU memory capacity. The user can accordingly make modifications to the code in case of more/less capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "gpu = GPUs[0]\n",
    "print(\"Total Available GPU memory: {} MB\".format(gpu.memoryTotal))\n",
    "print(\"Used GPU memory: {} MB\".format(gpu.memoryUsed))\n",
    "print(\"Total Free GPU memory: {} MB\".format(gpu.memoryFree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check library versions\n",
    "\n",
    "Here, we print the versions of tensorflow, keras and OpenCV versions to compare compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing installed tensorflow/keras/OpenCV versions\n",
    "print(\"Current OpenCV version:\", cv2.__version__)\n",
    "print(\"Using TensorFlow version:\", tf.__version__)\n",
    "print(\"Using Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "We use this cell to activate data augmentation. This step is highly advised to correct for any undesired bias in the model. We create a bool parameter. If set to True, we will perform data augmentation.\n",
    "\n",
    "(Note: This step may take a significant amount of time depending on the size of the original data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting data augmentation activation to True/False\n",
    "augment = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset building and Augmentation\n",
    "\n",
    "Here, we load the data from the *driving_log.csv* file and if required, augment the data by flipping the images in the opposite direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Start of dataset building\n",
    "## Read the csv file containing saved model data\n",
    "\n",
    "lines = []\n",
    "with open('./data/model_data.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "# empty list to save images        \n",
    "binary_images = []\n",
    "\n",
    "# lists to save polynomial measurements for left and right lanes\n",
    "\n",
    "left_measurements_a = []\n",
    "left_measurements_b = []\n",
    "left_measurements_c = []\n",
    "right_measurements_a = []\n",
    "right_measurements_b = []\n",
    "right_measurements_c = []\n",
    "\n",
    "# directory for accessing binary images\n",
    "directory = '../data_for_lane_detection/binary_images/'\n",
    "directory = '../data_for_lane_detection/lanelines_images/'\n",
    "directory = '../data_for_lane_detection/transformed_images/'\n",
    "\n",
    "\n",
    "\n",
    "if (augment):\n",
    "    print(\"Performing data augmentation by flipping the images ...\\n\")\n",
    "\n",
    "for line in lines:\n",
    "\n",
    "    # reading filesnames for binary images and lanelines images\n",
    "    fname_binary_img = directory + line[0].split('/')[-1]\n",
    "    fname_lanelines_img = directory + line[1].split('/')[-1]\n",
    "    fname_transformed_img = directory + line[2].split('/')[-1]\n",
    "\n",
    "    # reading images using opencv\n",
    "    bin_img = mpimg.imread(fname_binary_img)\n",
    "    laneline_img = mpimg.imread(fname_lanelines_img)\n",
    "    \n",
    "    # adding images to the lists\n",
    "    images.append(fname_binary_img)\n",
    "    images.append(fname_lanelines_img)\n",
    "    \n",
    "    # adding steering angles for center. left and right images\n",
    "\n",
    "    left_measurements_a.append(float(line[3]))\n",
    "    left_measurements_b.append(float(line[4]))\n",
    "    left_measurements_c.append(float(line[5]))\n",
    "    right_measurements_a.append(float(line[6]))\n",
    "    right_measurements_b.append(float(line[7]))\n",
    "    right_measurements_c.append(float(line[8]))\n",
    "\n",
    "    # only if data augmentation is required\n",
    "    if (augment):\n",
    "        \n",
    "        # this is where I perform data augmentation for images and angles\n",
    "        # binary_img_flipped = np.fliplr(fname_binary_img)\n",
    "        # images.append(binary_img_flipped)\n",
    "        \n",
    "\n",
    "        # laneline_img_flipped = np.fliplr(fname_laneline_img)\n",
    "        # images.append(lanelines_img_flipped)\n",
    "\n",
    "\n",
    "        transformed_img_flipped = np.fliplr(fname_transformed_img)\n",
    "        images.append(transformed_img_flipped)\n",
    "        \n",
    "        # flip the measurements\n",
    "        left_measurements_a_flip = -(float(line[3]))\n",
    "        left_measurements_b_flip = -(float(line[4]))\n",
    "        left_measurements_c_flip = -(float(line[5]))\n",
    "        right_measurements_a_flip = -(float(line[6]))\n",
    "        right_measurements_b_flip = -(float(line[7]))\n",
    "        right_measurements_c_flip = -(float(line[8]))\n",
    "        \n",
    "        # add the flipped measurements to the current measurements lists\n",
    "        left_measurements_a.append(left_measurements_a_flip)\n",
    "        left_measurements_b.append(left_measurements_b_flip)\n",
    "        left_measurements_c.append(left_measurements_c_flip)\n",
    "        right_measurements_a.append(right_measurements_a_flip)\n",
    "        right_measurements_b.append(right_measurements_b_flip)\n",
    "        right_measurements_c.append(right_measurements_c_flip)\n",
    "\n",
    "\n",
    "# define arrays for datasets\n",
    "\n",
    "X_train = np.array(images)\n",
    "\n",
    "left_measurements_a = np.array(left_measurements_a)\n",
    "left_measurements_b = np.array(left_measurements_b)\n",
    "left_measurements_c = np.array(left_measurements_c)\n",
    "right_measurements_a = np.array(right_measurements_a)\n",
    "right_measurements = np.array(right_measurements_b)\n",
    "right_measurements = np.array(right_measurements_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display sample flipped images\n",
    "\n",
    "This is the procedure I used to augment the data. The image was flipped from left to right. Here is a sample flipped image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a random image from the dataset\n",
    "\n",
    "idx = random.randint(0, len(X_train))\n",
    "img = X_train[idx]\n",
    "flipped_img = np.fliplr(img)\n",
    "\n",
    "left_a = left_measurements_a[idx]\n",
    "left_b = left_measurements_b[idx]\n",
    "left_c = left_measurements_c[idx]\n",
    "right_a = right_measurements_a[idx]\n",
    "right_b = right_measurements_b[idx]\n",
    "right_c = right_measurements_c[idx]\n",
    "\n",
    "# flip the lane polynomial coefficients\n",
    "flipped_left_a = -float(left_a)\n",
    "flipped_left_b = -float(left_b)\n",
    "flipped_left_c = -float(left_c)\n",
    "flipped_right_a = -float(left_a)\n",
    "flipped_right_b = -float(left_b)\n",
    "flipped_right_c = -float(left_c)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(40, 20))\n",
    "\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image' , fontsize=30)\n",
    "ax2.imshow(flipped_img)\n",
    "ax2.set_title('Flipped Image', fontsize=30)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Dataset information\n",
    "\n",
    "We will print information regarding the dataset here. We will also print information after data augmentation. For each laneline, we have a set of three polynomial coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print the dataset information\n",
    "def print_dataset_info():\n",
    "\n",
    "    if (augment):\n",
    "        # print out array shapes and details\n",
    "        print(\"Original Dataset information ---\\n\")\n",
    "        # print(\"Image shape: \", X_train[0][1])\n",
    "        print(\"Measurement Sets:\", 0.5*len(left_measurements_a))\n",
    "        print(\"Total images:\", 0.5*X_train.shape[0])\n",
    "        print()\n",
    "\n",
    "        print(\"Augmented Dataset information ---\\n\")\n",
    "        # print(\"Image shape: \", X_train[0][1])\n",
    "        print(\"Measurement sets after augmentation:\", len(left_measurements_a))\n",
    "        print(\"Total images after augmentation:\", X_train.shape[0])\n",
    "        print()\n",
    "    else:\n",
    "        # print out array shapes and details\n",
    "        print(\"Original Dataset information ---\\n\")\n",
    "        # print(\"Image shape: \", X_train[0][1])\n",
    "        print(\"Measurement Sets:\", 0.5*len(left_measurements_a))\n",
    "        print(\"Total images:\", 0.5*X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a sample image\n",
    "\n",
    "Here, we display a random sample image along with the drawn detected lanelines. We also print some characteristics of the lanelines polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(X_train))\n",
    "sample_img = X_train[idx]\n",
    "print(sample_img.shape)\n",
    "plt.imshow(sample_img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Measurement Sets - \" + str(left_measurements_a[idx]), fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "\n",
    "Now, we will define our Convolutional Neural Network here comtaining 6 convolutional layers, 4 fully connected layers and some dropout and lambda layers in between. We will use a dropout layer after the 6th convolutional layers and set the number of epochs to 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Start of Network Architecture\n",
    "# NVIDIA network architecture\n",
    "model = Sequential()\n",
    "\n",
    "# image preprocessing - normalizing the pixel values and cropping the image\n",
    "model.add(Lambda(lambda x:(x/127.5)-1.0, input_shape=(160,320,3)))\n",
    "# cropping top 50 pixels and 20 pixels from the bottom\n",
    "model.add(Cropping2D(cropping=((50,20),(0,0)), input_shape=(160,320,3)))\n",
    "\n",
    "# 1st Convolutional layer\n",
    "model.add(Conv2D(24, (5, 5), subsample = (2,2), activation=\"relu\"))\n",
    "# 2nd Convolutional layer\n",
    "model.add(Conv2D(36, (5, 5), subsample = (2,2), activation=\"relu\"))\n",
    "# 3rd Convolutional layer\n",
    "model.add(Conv2D(48, (5, 5), subsample = (2,2), activation=\"relu\"))\n",
    "# 4th Convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "# 5th Convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "# 6th Convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# flatten layers into a vector\n",
    "model.add(Flatten())\n",
    "\n",
    "# four fully connected layers\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# final layer to decide the 6 laneline polynomial coefficients\n",
    "model.add(Dense(6))\n",
    "\n",
    "model.compile(loss='mse', optimizer ='adam')\n",
    "\n",
    "# fit model with a validation set of 20%\n",
    "history_object = model.fit(X_train, steering_angles, validation_split=0.2, shuffle=True, epochs=10)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "\n",
    "Print the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Loss\n",
    "\n",
    "Print the training loss. We will also plot a graph of training loss (mean squared error loss) vs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history_object.history.keys())\n",
    "\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(0,0.1)\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
