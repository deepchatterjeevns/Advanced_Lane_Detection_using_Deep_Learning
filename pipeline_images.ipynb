{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding\n",
    "\n",
    "The purpose of this code is to calibrate our camera using the 20 chessboard images provided.\n",
    "\n",
    "A chessboard is used for camera calibration since its regular patterns of high contrast make it easy to detect automatically. So, if we use our camera to take multiple pictures of chessboard agaisnt a flat surface, then we will be able to detect any distortion by looking at the difference between the appartent size and shape of the squares of the chessboard pattern.\n",
    "\n",
    "We will start by importing all relevant libraries such as opencv, numpy required.\n",
    "\n",
    "The Project\n",
    "---\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import natsort\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a couple of random test images\n",
    "\n",
    "Let us display a random image and get its details, such as type, shape, no. of chanels information. We will display one image from daylight and night scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a couple of random images\n",
    "\n",
    "sample_image1 = mpimg.imread(\"test_images/test1.jpg\")\n",
    "sample_image2 = mpimg.imread(\"test_images/test7.jpg\")\n",
    "\n",
    "plt.figure(1)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(sample_image1)\n",
    "ax1.set_title(f'Night image - {sample_image2.shape}', fontsize=18)\n",
    "ax1.axis('off')\n",
    "ax2.imshow(sample_image2)\n",
    "ax2.set_title(f'Daylight image - {sample_image2.shape}', fontsize=18)\n",
    "ax2.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate Camera Function\n",
    "\n",
    "There are two main steps to this process: use chessboard images to obtain image points and object points, and then use the OpenCV functions cv2.calibrateCamera() and cv2.undistort() to compute the calibration and undistortion.\n",
    "\n",
    "More information on the use of these functions can be found on the OpenCV documentation website at the following location:\n",
    "\n",
    "[cv2.calibrateCamera()](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#calibratecamera)\n",
    "\n",
    "[cv2.undistort()](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html?highlight=undistort#cv2.undistort)\n",
    "\n",
    "Camera calibration for this project is already performed using a set of chessboard corner images in a separate jupyter notebook [camera_calculations.ipynb](./camera_calculations.ipynb)\n",
    "Here is a sample image -\n",
    "\n",
    "![image](./readme_images/test_undistortion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding Functions\n",
    "\n",
    "In this section, I have written functions for calculating parameters such as Sobel Intensity Gradients, Gradient magnitude, gradient direction, hue, lightness, saturation and applying threshold values to idetify lanelines in images. Each of these functions will extract a binary image with the applied threshold values.\n",
    "\n",
    "The idea behind writing different functions is that there is little extra effort involved and it is possible to use multiple combinations of these filters to achieve the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding functions\n",
    "# since we have evaludated earlier that HLS gives good image filtering results\n",
    "\n",
    "# this function returns a bindary image\n",
    "# this functions accepts a grayscale image as input\n",
    "def pixel_intensity(img, thresh = (0, 255)):\n",
    "\n",
    "    # THIS FUNCTION WORKS ONLY ON GRAYSCALE IAMGES!!!\n",
    "    # 1. apply threshold\n",
    "    intensity_image = np.zeros_like(img)\n",
    "    # scaled_pixel = np.uint8(255*img/255)\n",
    "    # 2. create a binary image\n",
    "    intensity_image[(img >= thresh[0]) & (img <= thresh[1])] = 1\n",
    "    return intensity_image\n",
    "\n",
    "\n",
    "# this function accepts a HLS format image\n",
    "def lightness_select(img, thresh = (120,255)):\n",
    "    \n",
    "    # 2. Apply threshold to lightness channel\n",
    "    l_channel = img[:,:,1]\n",
    "    # 3. Create empty array to store the binary output and apply threshold\n",
    "    lightness_image = np.zeros_like(l_channel)\n",
    "    lightness_image[(l_channel > thresh[0]) & (l_channel <= thresh[1])] = 1\n",
    "    return lightness_image\n",
    "\n",
    "\n",
    "\n",
    "# this function accepts a HLS format image\n",
    "def saturation_select(img, thresh = (100,255)):\n",
    "\n",
    "    # 2. apply threshold to saturation channel\n",
    "    s_channel = img[:,:,2]\n",
    "    # 3. create empty array to store the binary output and apply threshold\n",
    "    sat_image = np.zeros_like(s_channel)\n",
    "    sat_image[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return sat_image\n",
    "\n",
    "\n",
    "\n",
    "# this function accepts a RGB format image\n",
    "# function to create binary image sobel gradients in x and y direction\n",
    "def abs_sobel_thresh(img, orient = 'x', sobel_kernel = 5, thresh = (0,255)):\n",
    "\n",
    "    # 1. Applying the Sobel depending on x or y direction and getting the absolute value\n",
    "    if (orient == 'x'):\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    if (orient == 'y'):\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "    # 2. Scaling to 8-bit and converting to np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 3. Create mask of '1's where the sobel magnitude is > thresh_min and < thresh_max\n",
    "    sobel_image = np.zeros_like(scaled_sobel)\n",
    "    sobel_image[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return sobel_image\n",
    "\n",
    "\n",
    "\n",
    "# this function accepts a RGB format image\n",
    "# function to check binary image of sobel magnitude\n",
    "def mag_sobel(img, sobel_kernel=3, thresh = (0,255)):\n",
    "\n",
    "    # 1. Applying the Sobel (taking the derivative)\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    # 2. Magnitude of Sobel\n",
    "    mag_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # 3. Scaling to 8-bit and converting to np.uint8\n",
    "    scaled_sobel = np.uint8(255*mag_sobel/np.max(mag_sobel))\n",
    "    # 4. Create mask of '1's where the scaled gradient magnitude is > thresh_min and < thresh_max\n",
    "    sobel_mag_image = np.zeros_like(scaled_sobel)\n",
    "    sobel_mag_image[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return sobel_mag_image\n",
    "\n",
    "\n",
    "\n",
    "# this function accepts a RGB format image\n",
    "# function to compute threshold direction\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # 1. Applying the Sobel (taking the derivative)\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    # 2. Take absolute magnitude\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # 3. Take Tangent value\n",
    "    sobel_orient = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    # 4. Create mask of '1's where the orientation magnitude is > thresh_min and < thresh_max\n",
    "    dir_image = np.zeros_like(sobel_orient)\n",
    "    dir_image[(sobel_orient >= thresh[0]) & (sobel_orient <= thresh[1])] = 1\n",
    "    return dir_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Thresholding Function\n",
    "\n",
    "Using this function, we combine different threshold values together in a binary image. The different images for different thresholdings are saved in separate folders within the folder ***output_images/*** as per the name of the filter.\n",
    "\n",
    "\n",
    "##### Important:\n",
    "**Within the combined thresholding function, we call other individual thresholding functions starting from line 13 onwards. The thresholding parameters of all these functions need to be set here.**\n",
    "\n",
    "We also apply a masking threshold to our image to isolate only the region of interest and remove unneccessary pixel information such as scenery and problematic objects such as vehicle hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combined Thresholding Function\n",
    "\n",
    "\n",
    "def combined_threshold(img):\n",
    "\n",
    "    # convert to hls format and extract channels\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    hls = cv2.GaussianBlur(hls,(5,5),cv2.BORDER_DEFAULT)\n",
    "    s_channel = hls[:,:,2]\n",
    "\n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # apply Gaussian Blur with kernel size of 5\n",
    "    gray_blurred = cv2.GaussianBlur(gray,(5,5),cv2.BORDER_DEFAULT)\n",
    "    \n",
    "    # -------------------------- CALL FUNCTIONS FOR THRESHOLDING HERE! ----------------------------- #\n",
    "\n",
    "    # get pixel intensity binary image\n",
    "    # IMPORTANT: THIS FUNCION ACCEPTS GRAYSCALE IMAGES ONLY!!!\n",
    "    pixel_intensity_binary = pixel_intensity(gray, thresh = (150, 255))\n",
    "    \n",
    "    # applying thresholding and storing different filtered images\n",
    "    l_binary = lightness_select(hls, thresh = (140, 255))\n",
    "    s_binary = saturation_select(hls, thresh = (100, 255))\n",
    "\n",
    "    ksize = 5\n",
    "    gradx = abs_sobel_thresh(gray_blurred, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    # gradx_s_channel = abs_sobel_thresh(s_channel, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    # assuming lanelines are always at an angle between 30 and 45 degree to horizontal\n",
    "    dir_binary = dir_threshold(gray_blurred, sobel_kernel=ksize, thresh=(0.55, 0.7))\n",
    "\n",
    "\n",
    "    # ---------------------------- FUNCTION CALLS FOR THRESHOLDING END ------------------------------ #\n",
    "\n",
    "\n",
    "    # creating an empty binary image\n",
    "    combined_l_or_intensity = np.zeros_like(s_binary)\n",
    "    combined_l_or_intensity[((pixel_intensity_binary == 1) | (l_binary == 1))] = 1\n",
    "\n",
    "    combined_l_and_intensity = np.zeros_like(s_binary)\n",
    "    combined_l_and_intensity[((pixel_intensity_binary == 1) & (l_binary == 1))] = 1\n",
    "\n",
    "    # apply region of interest mask\n",
    "    height, width = combined_l_or_intensity.shape\n",
    "    mask = np.zeros_like(combined_l_or_intensity)\n",
    "    \n",
    "    # define the region as \n",
    "    region = np.array([[0, height-1], [840, 400], [1080, 400], [width-1, height-1]], dtype=np.int32)\n",
    "    # print(region)\n",
    "    cv2.fillPoly(mask, [region], 1)\n",
    "\n",
    "    masked = cv2.bitwise_and(combined_l_or_intensity, mask)\n",
    "    \n",
    "    # This section is only for saving the separated hls plots.\n",
    "    # This is commented out after running it once...\n",
    "\n",
    "    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(25, 10))\n",
    "    ax1.imshow(l_binary, cmap = 'gray')\n",
    "    ax1.set_title('Lightness', fontsize=18)\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(pixel_intensity_binary, cmap = 'gray')\n",
    "    ax2.set_title('Pixel Intensity', fontsize=18)\n",
    "    ax2.axis('off')\n",
    "    ax3.imshow(combined_l_or_intensity, cmap = 'gray')\n",
    "    ax3.set_title('Lightness or Intensity', fontsize=18)\n",
    "    ax3.axis('off')\n",
    "    ax4.imshow(combined_l_and_intensity, cmap = 'gray')\n",
    "    ax4.set_title('Lightness and Intensity', fontsize=18)\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # save hls separation plots\n",
    "    plt.savefig(('test_images_output/hls_plots/hls-plots-'+ i), cmap = 'gray') \n",
    "    \n",
    "    # save individual images for HSL plots, gradients, magnitude and direction\n",
    "    mpimg.imsave(('test_images_output/pixel_intensity/intensity-' + i), pixel_intensity_binary, cmap = 'gray')\n",
    "    mpimg.imsave(('test_images_output/gray/gray-' + i), gray, cmap = 'gray')\n",
    "    mpimg.imsave(('test_images_output/gray/gray-blurred-.jpg'), gray_blurred, cmap = 'gray')\n",
    "    \n",
    "    mpimg.imsave(('test_images_output/l_binary/l_binary-' + i), l_binary, cmap = 'gray')\n",
    "    mpimg.imsave(('test_images_output/s_binary/s_binary-' + i), s_binary, cmap = 'gray')\n",
    "    mpimg.imsave(('test_images_output/gradx_binary/gradx-' + i), gradx, cmap = 'gray')\n",
    "    mpimg.imsave(('test_images_output/dir_binary/direction-' + i), dir_binary, cmap = 'gray')\n",
    "    # mpimg.imsave(('test_images_output/test_images_gradx_binary/gradx-' + i), gradx, cmap = 'gray')\n",
    "    \n",
    "    # saving combined thresholded binary image\n",
    "    mpimg.imsave(('test_images_output/combined_lightness_or_intensity/combined-'+i),combined_l_or_intensity,cmap='gray')\n",
    "    mpimg.imsave(('test_images_output/combined_lightness_and_intensity/combined-'+i),combined_l_and_intensity,cmap='gray')\n",
    "\n",
    "    # end of saving images section, comment out above section after saving the images\n",
    "    \n",
    "    return masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transform\n",
    "\n",
    "After applying the thresholds, isolating the regions of interest and getting our binary image with identified lanelines, we apply the perspective transform to the image.\n",
    "We do this using [**cv2.getPerspectiveTransform(src, dst)**](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#getperspectivetransform).\n",
    "\n",
    "This function enables us to obtain a birds-eye view of the lanelines (from top) using which we will calculate lane curvatures.\n",
    "\n",
    "![image](./readme_images/points_perspective_transform.jpg)\n",
    "\n",
    "As can be seen in the image above, the following points have been selected to obtain perspective transformed image such that the lanelines appear as parallel.\n",
    "The pixel locations is selected are (860, 410), (1060, 410), (185, 825) and (1700, 825)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for applying perspective view on the images\n",
    "def perspective_view(img):\n",
    "\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # image points extracted from image approximately\n",
    "    bottom_left = [340, 825]\n",
    "    bottom_right = [1480, 825]\n",
    "    top_left = [880, 460]\n",
    "    top_right = [1040, 460]\n",
    "\n",
    "    src = np.float32([bottom_left, bottom_right, top_right, top_left])\n",
    "\n",
    "    pts = np.array([bottom_left, bottom_right, top_right, top_left], np.int32)\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    # create a copy of original img\n",
    "    imgpts = img.copy()\n",
    "    cv2.polylines(imgpts, [pts], True, (255, 0, 0), thickness = 3)\n",
    "\n",
    "    # choose four points in warped image so that the lines should appear as parallel\n",
    "    bottom_left_dst = [600, 1080]\n",
    "    bottom_right_dst = [1300, 1080]\n",
    "    top_left_dst = [600, 1]\n",
    "    top_right_dst = [1300, 1]\n",
    "\n",
    "    dst = np.float32([bottom_left_dst, bottom_right_dst, top_right_dst, top_left_dst])\n",
    "\n",
    "    # apply perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    # compute inverse perspective transform\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    # warp the image using perspective transform M\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting images from a directory\n",
    "\n",
    "Here I have prepared a directory to read images from. The directory contains multiple images which we will use for our thresholding, perspective transform and masking trials. We will also create a directory to save the output images. This directory will contain a separate folder structure for different thresholded images.\n",
    "Following is a list of folders that will be created for storing binary thresholded images:\n",
    "\n",
    "\n",
    "| Image Folder Name  | Stored Image details |\n",
    "| :---: | :---: | \n",
    "| test_images_output/gray | Grayscale Images |\n",
    "| test_images_output/gray_blurred | GrayScale Images with Gaussian Blur Applied |\n",
    "| test_images_output/dir_binary | Sobel Gradient Direction |\n",
    "| test_images_output/l_binary | Lightness channel threshold |\n",
    "| test_images_output/gradx_binary | Sobel gradient in X direction |\n",
    "| test_images_output/pixel_intensity | Pixel Intensity |\n",
    "| test_images_output/combined_lightness_and_intensity | Lightness and Pixel Intensity combined|\n",
    "| test_images_output/combined_lightness_or_intensity | Lightness or Pixel Intensity combined |\n",
    "| test_images_output/hls_plots | Separated Channel Plots of Intensity, L, and S channels |\n",
    "| test_images_output/undistorted | Undistorted Images |\n",
    "| test_images_output/thresholded_masked | Combined Threshold and Region of Interest Applied |\n",
    "| test_images_output/binary_warped | Thresholded, Undistorted and Warped|\n",
    "| test_images_output/masked | Thresholded, Undistorted, Transformed and Masked |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us test our functions on given test images\n",
    "directory = os.listdir(\"test_images/\")\n",
    "# sorting the images based on ids\n",
    "directory = natsort.natsorted(directory)\n",
    "print(directory)\n",
    "\n",
    "# define output directory here\n",
    "output_directory = \"test_images_output\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_directory)\n",
    "except FileExistsError:\n",
    "    print(f\"Folder with name {filename} already exists!!!\")\n",
    "    print(\"New images will be merged with the contents of the existing folder!\")\n",
    "    pass\n",
    "\n",
    "# create the rest of the folder structure\n",
    "os.mkdir(output_directory + '/binary_warped')\n",
    "os.mkdir(output_directory + '/combined_lightness_and_intensity')\n",
    "os.mkdir(output_directory + '/combined_lightness_or_intensity')\n",
    "os.mkdir(output_directory + '/dir_binary')\n",
    "\n",
    "os.mkdir(output_directory + '/gradx_binary')\n",
    "os.mkdir(output_directory + '/gray')\n",
    "os.mkdir(output_directory + '/gray_blurred')\n",
    "os.mkdir(output_directory + '/hls_plots')\n",
    "\n",
    "os.mkdir(output_directory + '/l_binary')\n",
    "os.mkdir(output_directory + '/pixel_intensity')\n",
    "os.mkdir(output_directory + '/s_binary')\n",
    "os.mkdir(output_directory + '/thresholded_masked')\n",
    "os.mkdir(output_directory + '/undistorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Pickle Data\n",
    "\n",
    "By printing matrix data from pickle here, we will confirm that undistortion matrices have been saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('pickle/dist_pickle.p', 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "data = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "print('Showing the pickled data:')\n",
    "\n",
    "mtx, dst = data.values()\n",
    "\n",
    "print(\"Saved distortion matrix coeffiencient:\")\n",
    "print(\"mtx = \", mtx)\n",
    "print()\n",
    "print(\"dst = \", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run functions for Combined Thresholding and Perspective Transform on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in directory:\n",
    "\n",
    "    img = mpimg.imread(os.path.join(\"test_images/\", i))\n",
    "\n",
    "    # undistort the image\n",
    "    undist = cv2.undistort(img, mtx, dst, None, mtx)\n",
    "    mpimg.imsave(('test_images_output/undistorted/undistorted-'+i), undist, cmap = 'gray')\n",
    "    \n",
    "    # apply combined threshold and get the masked thresholded image\n",
    "    thresholded_masked = combined_threshold(undist)\n",
    "    # saving masked images\n",
    "    mpimg.imsave(('test_images_output/thresholded_masked/masked-' + i), thresholded_masked, cmap = 'gray')\n",
    "\n",
    "    binary_warped, M, Minv = perspective_view(thresholded_masked)\n",
    "    mpimg.imsave(('test_images_output/binary_warped/binary_warped-'+i), binary_warped, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save mtx data for one image and plot the image\n",
    "\n",
    "We will plot the masked region for better visualization. The following plot gives us details across different channels and thresholding levels for one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in an image\n",
    "img = mpimg.imread(\"test_images/test8.jpg\")\n",
    "\n",
    "# undistort the original image using stored values from pickle\n",
    "undist_original = cv2.undistort(img, mtx, dst, None, mtx)\n",
    "\n",
    "# apply perspective view on the image\n",
    "warped_original, M, Minv = perspective_view(undist_original)\n",
    "\n",
    "# apply combined threshold\n",
    "combined_threshold_img = combined_threshold(undist_original)\n",
    "\n",
    "# apply perspective transform on the thresholded image\n",
    "warped, M, Minv = perspective_view(combined_threshold_img)\n",
    "\n",
    "plt.figure(2)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(25,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=20)\n",
    "ax1.axis('off')\n",
    "ax2.imshow(undist_original)\n",
    "ax2.set_title('Undistorted Image', fontsize=20)\n",
    "ax2.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Following images show the original, threholded and warped images...\")\n",
    "\n",
    "plt.figure(3)\n",
    "f, (ax3, ax4) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax3.imshow(warped_original)\n",
    "ax3.set_title('Warped Original', fontsize=20)\n",
    "ax3.axis('off')\n",
    "ax4.imshow(warped, cmap = 'gray')\n",
    "ax4.set_title('Warped Masked', fontsize=20)\n",
    "ax4.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# this is necessary only if images are taken using a different camera\n",
    "# than the one used for chessboard corners\n",
    "\n",
    "'''\n",
    "# save new pickle for test images from car's camera\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dst\"] = dst\n",
    "dist_pickle[\"M\"] = M\n",
    "dist_pickle[\"Minv\"] = Minv\n",
    "pickle.dump(dist_pickle, open(\"pickle/test_images_dist_pickle.p\", \"wb\"))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Lane Pixels\n",
    "#### Lane Finding Method: Peaks in a histogram\n",
    "\n",
    "After applying calibration, thresholding, and a perspective transform to a road image, we have a binary image where the lane lines stand out clearly. However, we still need to decide explicitly which pixels are part of the lines and which belong to the left line and which belong to the right line.\n",
    "\n",
    "We define this using the hist function from NumPy. With this histogram we are adding up the pixel values along each column in the image. In our thresholded binary image, pixels are either 0 or 1, so the two most prominent peaks in this histogram will be good indicators of the x-position of the base of the lane lines. We should get a output that looks as shown below.\n",
    "\n",
    "From here, we can use a sliding window, placed around the line centers, to find and follow the lines up to the top of the frame. We use the two highest peaks from our histogram as a starting point for determining where the lane lines are, and then use sliding windows moving upward in the image (further along the road) to determine where the lane lines go. Here is how it is done -\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will demo the histogram function\n",
    "img = mpimg.imread('test_images_output/binary_warped/binary_warped-test9.jpg')/255\n",
    "\n",
    "def hist(img):\n",
    "    # TO-DO: Grab only the bottom half of the image\n",
    "    # Lane lines are likely to be mostly vertical nearest to the car\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "    \n",
    "    # TO-DO: Sum across image pixels vertically - make sure to set `axis`\n",
    "    # i.e. the highest areas of vertical lines should be larger values\n",
    "    histogram = np.sum(bottom_half,axis=0)\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "# Create histogram of image binary activations\n",
    "\n",
    "histogram = hist(img[:,:,1])\n",
    "print(img.shape)\n",
    "\n",
    "# Visualize the resulting histogram\n",
    "plt.figure(3)\n",
    "plt.plot(histogram)\n",
    "plt.title('Plotted Histogram')\n",
    "\n",
    "plt.figure(4)\n",
    "plt.imshow(img)\n",
    "plt.title('Binary Warped Image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE\n",
    "\n",
    "### (for detecting lanelines and calculating road curvature)\n",
    "\n",
    "Here, we will establish a pipeline for detecting lanelines. We have created a class in a separate file *class_lanelines.py* which stores lanelines as objects along with their properties such as left and right fits.\n",
    "\n",
    "![image](readme_images/color-fit-lines.jpg)\n",
    "\n",
    "---\n",
    "1. We use the approach of sliding boxes from bottom to top in our histogram to detect laneline pixels and get their co-ordinates.\n",
    "2. Once we have found all our pixels belonging to each line through the sliding window method, it's time to fit a polynomial to the line. We store the x and y co-ordinates of these pixels in lists leftx, lefty, rightx and righty.\n",
    "3. After fitting a 2nd order polynomial using the NumPy function [np.polyfit()](https://numpy.org/doc/1.18/reference/generated/numpy.polyfit.html), we plot the lines using a linspace model on our image.\n",
    "4. Then, we calculate the radius of curvature using the following mathematical equations. The following formula gives us road curvature radius in pixels.\n",
    "\n",
    "![image](readme_images/formulae.png)\n",
    "\n",
    "5. We convert the road curvature from pixels to meters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lanelines Function\n",
    "\n",
    "This function contains code for detecting lanelines bases on our approach as explained above. Later on, this function will be used repeatedly for detecting lanelines in our video stream.\n",
    "\n",
    "I have also included functionality here to store previous lanelines data (2nd order equations) so that they can be used for successive frames. The variables ***avg_left_fit*** and ***avg_right_it*** are calculated based on the measurements of previous 12 frames. This helps the code to fit lanelines for the current frame even if they are not detected.\n",
    "\n",
    "For a vehicle traveling at maximum speed of 80mph (as per legal limits on most roads in US), the vehicle travels about 35 m/sec. The camera records the video stream at 30 frames/second. Hence, for our weighted averaging of 12 frames/second, the vehicle moves just about 14m (about 3 car lengths) and can be approximated. It can be safely assumed that lanelines will not change significantly during such a smaller distance. This value will be even smaller for lower speeds. Hence, it is safe for approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_lanelines(img):\n",
    "\n",
    "    # undistort the original image using stored values from pickle\n",
    "    undist_original = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # apply perspective view on the image\n",
    "    warped_original, M, Minv = perspective_view(undist_original)\n",
    "\n",
    "    # apply combined threshold\n",
    "    threshold = combined_threshold(img)\n",
    "    # undistort the thresholded image\n",
    "    undist_thresholded = cv2.undistort(threshold, mtx, dist, None, mtx)\n",
    "    # apply perspective transform on the thresholded image\n",
    "    warped, M, Minv = perspective_view(undist_thresholded)\n",
    "\n",
    "    # these will be empty for the first iteration and they will store the values of lane fits from previous iterations\n",
    "    # declaring lane fits as global variables so that they can be modified from anywhere in the code\n",
    "    \n",
    "    # list storing left and right lanefit values from previous frames\n",
    "    global prev_left_fits\n",
    "    global prev_right_fits\n",
    "\n",
    "    # average of previous 10 lanefits\n",
    "    global average_left_fit\n",
    "    global average_right_fit\n",
    "\n",
    "    # initialize the lanelines class by giving inputs from previous iteration\n",
    "    binary_warped = LaneLines(warped, average_left_fit, average_right_fit)\n",
    "\n",
    "    # calculate the left and right lane fits\n",
    "    out_img, leftfit, rightfit = binary_warped.find_lane_pixels()\n",
    "\n",
    "    # we convert our left and right fits from shape (3,) to an array of shape (1,3) to append it to our lists\n",
    "    previous_left_fit_array = np.array([leftfit])\n",
    "    previous_right_fit_array = np.array([rightfit])\n",
    "\n",
    "    # we add fits from previous detections to our list of previous fits\n",
    "    prev_left_fits = np.append(prev_left_fits, previous_left_fit_array, axis = 0)\n",
    "    prev_right_fits = np.append(prev_right_fits, previous_right_fit_array, axis = 0)\n",
    "\n",
    "    # we ensure that the list doesn't take into account more than 15 previous measurements\n",
    "    # we delete the initial element of the array if it does, i.e. - earliest element in the array\n",
    "    if (prev_left_fits.shape[0] > 15):\n",
    "        prev_left_fits = np.delete(prev_left_fits, 0, axis = 0)\n",
    "    if(prev_right_fits.shape[0] > 15):\n",
    "        prev_right_fits = np.delete(prev_right_fits, 0, axis = 0)\n",
    "\n",
    "    # compute average of past 10 best fits and pass them over to next iteration\n",
    "    average_left_fit = np.mean(prev_left_fits, axis = 0)\n",
    "    average_right_fit = np.mean(prev_right_fits, axis = 0)\n",
    "\n",
    "    # get the left and right lane radii\n",
    "    center_offset, left_radius, right_radius = binary_warped.measure_curvature_pixels()\n",
    "\n",
    "    # calculation of road curvature\n",
    "    road_radius = round(0.5*(left_radius+right_radius), 2)\n",
    "    center_offset = round(center_offset, 2)\n",
    "    road_curvature = \"Road Curvature = \" + str(road_radius) + \"m\"\n",
    "    center_offset = \"Center Offset = \" + str(center_offset) + \"m\"\n",
    "\n",
    "    # print(\"Left = \", left_radius)\n",
    "    # print(\"Right = \", right_radius)\n",
    "    # print(\"Road Curvature = \", road_radius)\n",
    "\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([binary_warped.left_fitx, binary_warped.ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([binary_warped.right_fitx, binary_warped.ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    unwarped = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist_original, 1, unwarped, 0.3, 0)\n",
    "\n",
    "    # this prints the value of road curvature onto the output image\n",
    "    cv2.putText(result, road_curvature, (80, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), thickness=2)\n",
    "\n",
    "    # this prints the value of center offset onto the output image\n",
    "    cv2.putText(result, center_offset, (80, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), thickness=2)\n",
    "\n",
    "    # VISUALIZATION\n",
    "    # THIS SECTION SHOULD BE COMMENTED OUT WHEN RUNNING ON VIDEO STREAM\n",
    "\n",
    "    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(25, 10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=20)\n",
    "    ax2.imshow(threshold, cmap = 'gray')\n",
    "    ax2.set_title('Original Thresholded', fontsize=20)\n",
    "    ax3.imshow(warped_original, cmap = 'gray')\n",
    "    ax3.set_title('Warped Perspective', fontsize=20)\n",
    "    ax4.imshow(out_img)\n",
    "    ax4.set_title('Sliding Boxes', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing our pipeline on a couple of images\n",
    "\n",
    "Here, we will call our function ***advanced_lanelines*** and execute it on a test image and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables needed in the global scope\n",
    "previous_left_fit = None\n",
    "previous_right_fit = None\n",
    "\n",
    "# initialize empty 1*3 empty arrays for calculating the storing lane fit data of previous frames\n",
    "prev_left_fits = np.empty([1,3])\n",
    "prev_right_fits = np.empty([1,3])\n",
    "\n",
    "# intitialize the average left and right fit empty lists - these will be updated in every iteration\n",
    "average_left_fit = []\n",
    "average_right_fit = []\n",
    "\n",
    "# import the lanelines class\n",
    "from class_lanelines import LaneLines\n",
    "\n",
    "test_image = mpimg.imread(\"test_images/test2.jpg\")\n",
    "lane_image = advanced_lanelines(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Result\n",
    "\n",
    "Final resulting image showing lane markings and road curvature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lane_image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
