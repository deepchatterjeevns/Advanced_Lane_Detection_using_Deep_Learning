{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding\n",
    "\n",
    "The purpose of this jupyter notebook is to identify lanelines on a given video stream and save the perspective transformed images along with the fitted polynomial coefficients in a .csv file.\n",
    "\n",
    "\n",
    "We will start by importing all relevant libraries such as opencv, numpy required.\n",
    "\n",
    "\n",
    "The Steps:\n",
    "---\n",
    "\n",
    "The steps followed in this notebook are the following:\n",
    "\n",
    "* Apply a distortion correction to raw image frames extracted from video\n",
    "* Use color transforms, gradients, etc. to create a thresholded binary image\n",
    "* Apply a perspective transform to the thresholded binary image (\"birds-eye view\")\n",
    "* Detect lane pixels and fit a polynomial to the individual pixels to find the laneline\n",
    "* Save the thresholded perspective transformed image in a separate folder along with the polynomial coefficients in a .csv file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "Import all necessary libraries. We will be working with OpenCV, Matplotlib, Glob, Pickle, Natsort and NumPy libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import csv\n",
    "import natsort\n",
    "import pickle\n",
    "import moviepy\n",
    "import imageio\n",
    "import progressbar\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import moviepy.editor as mpy\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding Functions\n",
    "\n",
    "In this section, I have written functions for calculating parameters such as Sobel Intensity Gradients, Gradient magnitude, gradient direction, hue, lightness, saturation and applying threshold values to idetify lanelines in images. Each of these functions will extract a binary image with the applied threshold values.\n",
    "\n",
    "The idea behind writing different functions is that there is little extra effort involved and it is possible to use multiple combinations of these filters to achieve the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding functions\n",
    "# since we have evaludated earlier that HLS gives good image filtering results\n",
    "\n",
    "# this functions accepts a grayscale image as input\n",
    "def pixel_intensity(img, thresh = (0, 255)):\n",
    "\n",
    "    # THIS FUNCTION WORKS ONLY ON GRAYSCALE IAMGES!!!\n",
    "    # 1. apply threshold\n",
    "    intensity_image = np.zeros_like(img)\n",
    "    # 2. create a binary image\n",
    "    intensity_image[(img >= thresh[0]) & (img <= thresh[1])] = 1\n",
    "    return intensity_image\n",
    "\n",
    "\n",
    "\n",
    "# this function accepts a HLS format image\n",
    "def lightness_select(img, thresh = (120,255)):\n",
    "    \n",
    "    # 2. Apply threshold to lightness channel\n",
    "    l_channel = img[:,:,1]\n",
    "    # 3. Create empty array to store the binary output and apply threshold\n",
    "    lightness_image = np.zeros_like(l_channel)\n",
    "    lightness_image[(l_channel >= thresh[0]) & (l_channel <= thresh[1])] = 1\n",
    "    return lightness_image\n",
    "\n",
    "\n",
    "\n",
    "# this function accepts a HLS format image\n",
    "def saturation_select(img, thresh = (100,255)):\n",
    "\n",
    "    # 2. apply threshold to saturation channel\n",
    "    s_channel = img[:,:,2]\n",
    "    # 3. create empty array to store the binary output and apply threshold\n",
    "    sat_image = np.zeros_like(s_channel)\n",
    "    sat_image[(s_channel >= thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return sat_image\n",
    "\n",
    "\n",
    "\n",
    "# this function accepts a GRAYSCALE format image\n",
    "# function to create binary image sobel gradients in x and y direction\n",
    "def abs_sobel_thresh(img, orient = 'x', sobel_kernel = 5, thresh = (0,255)):\n",
    "\n",
    "    # 1. Applying the Sobel depending on x or y direction and getting the absolute value\n",
    "    if (orient == 'x'):\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    if (orient == 'y'):\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "    # 2. Scaling to 8-bit and converting to np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 3. Create mask of '1's where the sobel magnitude is > thresh_min and < thresh_max\n",
    "    sobel_image = np.zeros_like(scaled_sobel)\n",
    "    sobel_image[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return sobel_image\n",
    "\n",
    "\n",
    "\n",
    "# this function accepts a RGB format image\n",
    "# function to check binary image of sobel magnitude\n",
    "def mag_sobel(img, sobel_kernel=3, thresh = (0,255)):\n",
    "\n",
    "    # 1. Applying the Sobel (taking the derivative)\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    # 2. Magnitude of Sobel\n",
    "    mag_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # 3. Scaling to 8-bit and converting to np.uint8\n",
    "    scaled_sobel = np.uint8(255*mag_sobel/np.max(mag_sobel))\n",
    "    # 4. Create mask of '1's where the scaled gradient magnitude is > thresh_min and < thresh_max\n",
    "    sobel_mag_image = np.zeros_like(scaled_sobel)\n",
    "    sobel_mag_image[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return sobel_mag_image\n",
    "\n",
    "\n",
    "\n",
    "# this function accepts a RGB format image\n",
    "# function to compute threshold direction\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # 1. Applying the Sobel (taking the derivative)\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    # 2. Take absolute magnitude\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # 3. Take Tangent value\n",
    "    sobel_orient = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    # 4. Create mask of '1's where the orientation magnitude is > thresh_min and < thresh_max\n",
    "    dir_image = np.zeros_like(sobel_orient)\n",
    "    dir_image[(sobel_orient >= thresh[0]) & (sobel_orient <= thresh[1])] = 1\n",
    "    return dir_image\n",
    "\n",
    "\n",
    "\n",
    "# this function accepts a HSV format image\n",
    "# function to compute threshold direction\n",
    "def value_select(img, thresh=(0,255)):\n",
    "    \n",
    "    # 2. apply threshold to saturation channel\n",
    "    v_channel = img[:,:,2]\n",
    "    # 3. create empty array to store the binary output and apply threshold\n",
    "    val_image = np.zeros_like(v_channel)\n",
    "    val_image[(v_channel > thresh[0]) & (v_channel <= thresh[1])] = 1\n",
    "    return val_image\n",
    "\n",
    "\n",
    "\n",
    "# this function uses Canny Edge Detection\n",
    "# from OpenCV and exports a binary image\n",
    "def canny_edge(img, thresh=(50, 150)):\n",
    "    \n",
    "    canny_image = cv2.Canny(img, thresh[0], thresh[1])\n",
    "    return canny_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Thresholding Function\n",
    "\n",
    "##### Important:\n",
    "**Within the combined thresholding function, we call other individual thresholding functions starting from line 13 onwards. The thresholding parameters of all these functions need to be set here.**\n",
    "\n",
    "We also apply a masking threshold to our image to isolate only the region of interest and remove unneccessary pixel information such as scenery and problematic objects such as vehicle hood. For more details on this, check the [pipeline_mages.ipynb](pipeline_images.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combined Thresholding Function\n",
    "def combined_threshold(img):\n",
    "\n",
    "    # ----------------------------------- IMAGES PREPROCESSING ------------------------------------- #\n",
    "    \n",
    "    # apply Gaussian Blur to remove noise from the image\n",
    "    img_blurred = cv2.GaussianBlur(img,(3,3),cv2.BORDER_DEFAULT)\n",
    "    # convert to HLS format\n",
    "    hls= cv2.cvtColor(img_blurred, cv2.COLOR_RGB2HLS)\n",
    "    # convert image to grayscale\n",
    "    gray_blurred = cv2.cvtColor(img_blurred, cv2.COLOR_RGB2GRAY)\n",
    "    # convert to HSV format\n",
    "    hsv = cv2.cvtColor(img_blurred, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    We will calculate the overall pixel intensity of the road by \n",
    "    selecting a slice of the road from the center of the image.\n",
    "    This step will help us to set the correct settings in case \n",
    "    of white paved concrete against dark paved concrete paved roads.\n",
    "    '''\n",
    "\n",
    "    avg_pixel_intensity = np.mean(gray_blurred[760:810,900:1080])\n",
    "    avg_pixel_intensity = int(avg_pixel_intensity)\n",
    "\n",
    "    if (avg_pixel_intensity < 100):\n",
    "        road_texture = 'dark'\n",
    "    else:\n",
    "        road_texture = 'white'\n",
    "    \n",
    "    # old values = 155, 130, 180 (pixel intensity, lightness, value )\n",
    "    # -------------------------- CALL FUNCTIONS FOR THRESHOLDING HERE! ----------------------------- #\n",
    "    if (road_texture == \"dark\"):\n",
    "        pixel_intensity_binary = pixel_intensity(gray_blurred, thresh = (145, 255))\n",
    "    else:\n",
    "        pixel_intensity_binary = pixel_intensity(gray_blurred, thresh = (220, 255))\n",
    "    \n",
    "    \n",
    "    if (road_texture == \"dark\"):\n",
    "        l_binary = lightness_select(hls, thresh = (120, 255))\n",
    "    else:\n",
    "        l_binary = lightness_select(hls, thresh = (160, 255))\n",
    "    \n",
    "    \n",
    "    gradx = abs_sobel_thresh(gray_blurred, orient='x', thresh=(35, 100))\n",
    "    grady = abs_sobel_thresh(gray_blurred, orient='y', thresh=(35, 100))\n",
    "    \n",
    "    # originally 150 and 215 values\n",
    "    if (road_texture == \"dark\"):\n",
    "        v_binary = value_select(hsv, thresh=(150,255))\n",
    "    else:\n",
    "        v_binary = value_select(hsv, thresh=(215,255))\n",
    "        \n",
    "    \n",
    "    # ------------------------------ FUNCTION CALLS FOR THRESHOLDING END ------------------------------ #\n",
    "    #####################################################################################################\n",
    "    \n",
    "    # ------------------------------ BEGINNING OF COMBINED THRESHOLDING ------------------------------- #\n",
    "    \n",
    "    # combining both x and y gradients\n",
    "    comb_x_or_y = np.zeros_like(gradx)\n",
    "    comb_x_or_y[((gradx == 1) | (grady == 1))] = 1\n",
    "    \n",
    "    # creating a combined thresholded image\n",
    "    combined_l_or_intensity = np.zeros_like(pixel_intensity_binary)\n",
    "    combined_l_or_intensity[((pixel_intensity_binary == 1) | (l_binary == 1))] = 1\n",
    "\n",
    "    # combined_l_and_intensity = np.zeros_like(pixel_intensity_binary)\n",
    "    # combined_l_and_intensity[((pixel_intensity_binary == 1) & (l_binary == 1))] = 1\n",
    "\n",
    "    combined1 = np.zeros_like(gray_blurred)\n",
    "    combined1[((combined_l_or_intensity == 1) & (v_binary == 1))] = 1\n",
    "    \n",
    "    canny_img = canny_edge(gray_blurred, thresh=(50,150))\n",
    "    \n",
    "    combined2 = np.zeros_like(gray_blurred)\n",
    "    combined2[((canny_img == 1) | (comb_x_or_y == 1))] = 1\n",
    "    \n",
    "    \n",
    "    # THIS IS THE FINAL THRESHOLDED IMAGE\n",
    "    final_thresholded = np.zeros_like(gray_blurred)\n",
    "    final_thresholded[((combined1 == 1) | (combined2 == 1))] = 1\n",
    "    \n",
    "    \n",
    "    # apply region of interest mask\n",
    "    height, width = final_thresholded.shape\n",
    "    mask = np.zeros_like(final_thresholded)\n",
    "    \n",
    "    region = np.array([[300, height-112], [880, 710], [1050, 710], [width-200, height-112]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, [region], 1)\n",
    "\n",
    "    masked = cv2.bitwise_and(final_thresholded, mask)\n",
    "\n",
    "    \n",
    "    return masked, canny_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transform\n",
    "\n",
    "After applying the thresholds, isolating the regions of interest and getting our binary image with identified lanelines, we apply the perspective transform to the image.\n",
    "We do this using [**cv2.getPerspectiveTransform(src, dst)**](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#getperspectivetransform).\n",
    "\n",
    "This function enables us to obtain a birds-eye view of the lanelines (from top) using which we will calculate lane curvatures.\n",
    "\n",
    "![image](./readme_images/points_perspective_transform.jpg)\n",
    "\n",
    "As can be seen in the image above, the following points have been selected to obtain perspective transformed image such that the lanelines appear as parallel.\n",
    "The pixel locations is selected are (340, 825), (1480, 825), (880, 460) and (1040, 460)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for applying perspective view on the images\n",
    "def perspective_view(img):\n",
    "\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # image points extracted from image approximately\n",
    "    bottom_left = [480, 960]\n",
    "    bottom_right = [1445, 960]\n",
    "    top_left = [900, 710]\n",
    "    top_right = [1024, 710]\n",
    "\n",
    "    src = np.float32([bottom_left, bottom_right, top_right, top_left])\n",
    "\n",
    "    pts = np.array([bottom_left, bottom_right, top_right, top_left], np.int32)\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "\n",
    "    # choose four points in warped image so that the lines should appear as parallel\n",
    "    bottom_left_dst = [600, 1080]\n",
    "    bottom_right_dst = [1300, 1080]\n",
    "    top_left_dst = [600, 1]\n",
    "    top_right_dst = [1300, 1]\n",
    "\n",
    "    dst = np.float32([bottom_left_dst, bottom_right_dst, top_right_dst, top_left_dst])\n",
    "\n",
    "    # apply perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    # compute inverse perspective transform\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    # warp the image using perspective transform M\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Pickle Data\n",
    "\n",
    "Load data from pickle here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('pickle/dist_pickle.p', 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "data = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "mtx, dst = data.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Lanelines Function\n",
    "\n",
    "This function contains code for detecting lanelines bases on our approach as explained above. Later on, this function will be used repeatedly for detecting lanelines in our video stream.\n",
    "\n",
    "I have also included functionality here to store previous lanelines data (2nd order equations) so that they can be used for successive frames. The variables ***avg_left_fit*** and ***avg_right_it*** are calculated based on the measurements of previous 12 frames. This helps the code to fit lanelines for the current frame even if they are not detected.\n",
    "\n",
    "For a vehicle traveling at maximum speed of 80mph (as per legal limits on most roads in US), the vehicle travels about 35 m/sec. The camera records the video stream at 30 frames/second. Hence, for our weighted averaging of 12 frames/second, the vehicle moves just about 14m (about 3 car lengths) and can be approximated. It can be safely assumed that lanelines will not change significantly during such a smaller distance. This value will be even smaller for lower speeds. Hence, it is safe for approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def advanced_lanelines(img):\n",
    "\n",
    "    # undistort the original image using stored values from pickle\n",
    "    undist_original = cv2.undistort(img, mtx, dst, None, mtx)\n",
    "    \n",
    "    # apply perspective transform on the thresholded image\n",
    "    transformed_img, M, Minv = perspective_view(undist_original)\n",
    "    \n",
    "    # apply combined threshold\n",
    "    threshold, canny_img = combined_threshold(img)\n",
    "    \n",
    "    # undistort the thresholded image\n",
    "    undist_thresholded = cv2.undistort(threshold, mtx, dst, None, mtx)\n",
    "    \n",
    "    # apply perspective transform on the thresholded image\n",
    "    warped, M, Minv = perspective_view(undist_thresholded)\n",
    "    \n",
    "    # list storing left and right lanefit values from previous frames\n",
    "    global previous_left_fit\n",
    "    global previous_right_fit\n",
    "    \n",
    "    global prev_left_fits\n",
    "    global prev_right_fits\n",
    "\n",
    "    # average of previous 10 lanefits\n",
    "    global average_left_fit\n",
    "    global average_right_fit\n",
    "    \n",
    "    # previous detection variable\n",
    "    global previous_detection\n",
    "\n",
    "    # set this value to True if Radius of the road is to be calculated #\n",
    "    calculate_radius = False\n",
    "    \n",
    "    if (calculate_radius):\n",
    "        global past_radii\n",
    "\n",
    "    # initialize the lanelines class by giving inputs from previous iteration\n",
    "    binary_warped = LaneLines(warped, average_left_fit, average_right_fit, previous_left_fit,\\\n",
    "                              previous_right_fit, previous_detection)\n",
    "\n",
    "    # calculate the left and right lane fits\n",
    "    out_img, leftfit, rightfit, detected = binary_warped.find_lane_pixels()\n",
    "\n",
    "    # we convert our left and right fits from shape (3,) to an array of shape (1,3) to append it to our lists\n",
    "    previous_left_fit_array = np.array([leftfit])\n",
    "    previous_right_fit_array = np.array([rightfit])\n",
    "    previous_detection = detected\n",
    "\n",
    "    # we add fits from previous detections to our list of previous fits\n",
    "    prev_left_fits = np.append(prev_left_fits, previous_left_fit_array, axis = 0)\n",
    "    prev_right_fits = np.append(prev_right_fits, previous_right_fit_array, axis = 0)\n",
    "\n",
    "    # we ensure that the list doesn't take into account more than 10 previous measurements\n",
    "    # we delete the initial element of the array if it does, i.e. - earliest element in the array\n",
    "    if (prev_left_fits.shape[0] > 10):\n",
    "        prev_left_fits = np.delete(prev_left_fits, 0, axis = 0)\n",
    "    if(prev_right_fits.shape[0] > 10):\n",
    "        prev_right_fits = np.delete(prev_right_fits, 0, axis = 0)\n",
    "\n",
    "    # compute average of past 5 best fits and pass them over to next iteration\n",
    "    average_left_fit = np.mean(prev_left_fits, axis = 0)\n",
    "    average_right_fit = np.mean(prev_right_fits, axis = 0)\n",
    "    \n",
    "    if (calculate_radius):\n",
    "        # get the left and right lane radii\n",
    "        center_offset, left_radius, right_radius = binary_warped.measure_curvature()\n",
    "\n",
    "        # START OF RADIUS CALCULATIONS\n",
    "        # calculation of road curvature\n",
    "        current_road_radius = 0.5*(left_radius+right_radius)\n",
    "\n",
    "        # Storing past five frame's radii \n",
    "        past_radii.append(current_road_radius)\n",
    "        # calculate weighted average of radii to reduce noisy measurements\n",
    "        road_radius = sum(past_radii)/len(past_radii)\n",
    "\n",
    "        # if no outliers are detected then, delete the oldest value\n",
    "        if (len(past_radii) > 10):\n",
    "            past_radii.pop(0)\n",
    "\n",
    "        # calculate mean radius\n",
    "        road_radius = sum(past_radii)/len(past_radii)\n",
    "        road_radius = round(road_radius)\n",
    "\n",
    "        center_offset = round(center_offset, 2)\n",
    "        road_curvature = \"Road Curvature = \" + str(road_radius) + \"m\"\n",
    "        center_offset = \"Center Offset = \" + str(center_offset) + \"m\"\n",
    "    \n",
    "    '''\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([binary_warped.left_fitx, binary_warped.ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([binary_warped.right_fitx, binary_warped.ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "    # Draw the lanelines onto the image\n",
    "    cv2.polylines(color_warp, np.int32([pts_left]), isClosed=False, color=(255,0,0), thickness=20)\n",
    "    cv2.polylines(color_warp, np.int32([pts_right]), isClosed=False, color=(0,0,255), thickness=20)\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    unwarped = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist_original, 1, unwarped, 0.3, 0)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    previous_left_fit = leftfit\n",
    "    previous_right_fit = rightfit\n",
    "    \n",
    "\n",
    "    # returning original road image, thresholded image, left and right fits\n",
    "    return transformed_img, warped, leftfit, rightfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the algorithm on a Video Stream\n",
    "\n",
    "To run this pipeline on a video stream, we need to import the necessary libraries for video files reading. We will test our pipeline on a short 15 second video file to make sure that all our functions are working correctly and check the output.\n",
    "\n",
    "The following image is a sample of the generated video that we will get.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the lanelines class\n",
    "from class_lanelines_1 import LaneLines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract images from video files and save polynomial coefficients\n",
    "\n",
    "Now, we will run this process on all the video files and instead of creating output video files, we will save the individual frame images to a folder. We will run our laneline detection procedure on these image frames and save the polynomial coefficients along with the corresponding image path to a .csv file.\n",
    "\n",
    "Later on, we will use the saved data to train the neural network model. We will provide the neural network model with the thresholded binary image along with the polynomial coefficients.\n",
    "\n",
    "We will start by importing the necessary libraries for extracting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Images will be extracted from 6 video files...\n",
      "\n",
      "Video processing started...\n",
      "\n",
      "Images will be extracted and thresholded binary images will be saved ...\n",
      "\n",
      "Binary images will be saved ...\n",
      "Transformed images will be saved ...\n",
      "Working on video file ../data_for_lane_detection/videos\\video16.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 frames could not be processed!\n",
      "Extraction complete for file ../data_for_lane_detection/videos\\video16.mp4 ...\n",
      "409 images extracted from file ../data_for_lane_detection/videos\\video16.mp4 ...\n",
      "\n",
      "Time required = 00:09:22.37\n",
      "\n",
      "\n",
      "Working on video file ../data_for_lane_detection/videos\\video18.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 frames could not be processed!\n",
      "Extraction complete for file ../data_for_lane_detection/videos\\video18.mp4 ...\n",
      "487 images extracted from file ../data_for_lane_detection/videos\\video18.mp4 ...\n",
      "\n",
      "Time required = 00:05:49.18\n",
      "\n",
      "\n",
      "Working on video file ../data_for_lane_detection/videos\\video4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 frames could not be processed!\n",
      "Extraction complete for file ../data_for_lane_detection/videos\\video4.mp4 ...\n",
      "1970 images extracted from file ../data_for_lane_detection/videos\\video4.mp4 ...\n",
      "\n",
      "Time required = 00:00:28.93\n",
      "\n",
      "\n",
      "Working on video file ../data_for_lane_detection/videos\\video5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 frames could not be processed!\n",
      "Extraction complete for file ../data_for_lane_detection/videos\\video5.mp4 ...\n",
      "1878 images extracted from file ../data_for_lane_detection/videos\\video5.mp4 ...\n",
      "\n",
      "Time required = 00:00:32.02\n",
      "\n",
      "\n",
      "Working on video file ../data_for_lane_detection/videos\\video8.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 frames could not be processed!\n",
      "Extraction complete for file ../data_for_lane_detection/videos\\video8.mp4 ...\n",
      "1741 images extracted from file ../data_for_lane_detection/videos\\video8.mp4 ...\n",
      "\n",
      "Time required = 00:20:44.12\n",
      "\n",
      "\n",
      "Working on video file ../data_for_lane_detection/videos\\video9.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 frames could not be processed!\n",
      "Extraction complete for file ../data_for_lane_detection/videos\\video9.mp4 ...\n",
      "388 images extracted from file ../data_for_lane_detection/videos\\video9.mp4 ...\n",
      "\n",
      "Time required = 00:05:05.24\n",
      "\n",
      "\n",
      "3101 image data saved for 6 video files ...\n",
      "Done!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# directory for video files\n",
    "file_list = glob.glob(\"../data_for_lane_detection/videos/*\")\n",
    "total_videos = len(file_list)\n",
    "\n",
    "# image index number for a million range for large data sets\n",
    "i = 1000001\n",
    "\n",
    "print(f\"\\nImages will be extracted from {total_videos} video files...\\n\")\n",
    "print(\"Video processing started...\\n\")\n",
    "print(\"Images will be extracted and thresholded binary images will be saved ...\\n\")\n",
    "\n",
    "\n",
    "# create a directory with the same name and '-images' and 'binary_images' for saving images\n",
    "try:\n",
    "    os.mkdir(\"../data_for_lane_detection/binary_images/\")\n",
    "    print(\"Binary images will be saved ...\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder with the name binary_images already exists!!!\")\n",
    "    print(\"Warning!!! - Existing files will be overwritten!!!\")\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"../data_for_lane_detection/transformed_images/\")\n",
    "    print(\"Transformed images will be saved ...\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder with the name transformed_images already exists!!!\")\n",
    "    print(\"Warning!!! - Existing files will be overwritten!!!\")\n",
    "    pass\n",
    "\n",
    "time.sleep(3.0)\n",
    "\n",
    "folder_rel_path_transformed = \"../data_for_lane_detection/transformed_images/\"\n",
    "folder_rel_path_binary = \"../data_for_lane_detection/binary_images/\"\n",
    "\n",
    "####################################################################################################\n",
    "##################################  Start of Video Processing  #####################################\n",
    "####################################################################################################\n",
    "\n",
    "# define functions to save the images\n",
    "def save_transformed_img(img, img_number, folder_rel_path_transformed):\n",
    "    transformed_image = cv2.resize(img, None, fx = 0.25, fy = 0.25, interpolation = cv2.INTER_CUBIC)\n",
    "    transform_file_name = folder_rel_path_transformed + 'transform_img_' + str(img_number) + '.jpg'\n",
    "    # full absolute path of the file\n",
    "    trans_abs_path = os.path.abspath(transform_file_name)\n",
    "    cv2.imwrite(transform_file_name, transformed_image)\n",
    "    return trans_abs_path\n",
    "\n",
    "def save_binary_img(img, img_number, folder_rel_path_binary):\n",
    "    # change resolution by adjusting fx and fy values\n",
    "    binary_image = cv2.resize(img, None, fx = 0.25, fy = 0.25, interpolation = cv2.INTER_CUBIC)\n",
    "    # assign file name here ...\n",
    "    bin_file_name = folder_rel_path_binary + 'bin_img_' + str(i) + '.jpg'\n",
    "    # full absolute path of the file\n",
    "    bin_abs_path = os.path.abspath(bin_file_name)\n",
    "    # path to write binary perspective transformed images to ...\n",
    "    mpimg.imsave(bin_file_name, binary_image, cmap=\"gray\")\n",
    "    return bin_abs_path\n",
    "\n",
    "with open('model_data.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile)\n",
    "    for item in file_list:\n",
    "        \n",
    "        ######## ------- These parameters need to be initialized for every file -------- ########\n",
    "        start_time = time.time()\n",
    "        # define variables needed in the global scope\n",
    "        # these variables store the left and right fits from the previous frame\n",
    "        previous_left_fit = None\n",
    "        previous_right_fit = None\n",
    "        previous_detection = False\n",
    "\n",
    "        # these variables store the average left and right fits for past 10 frames\n",
    "        previous_avg_left_fit = None\n",
    "        previous_avg_right_fit = None\n",
    "\n",
    "        # initialize empty 1*3 empty arrays for storing lane fit data of previous 10 frames\n",
    "        prev_left_fits = np.empty([1,3])\n",
    "        prev_right_fits = np.empty([1,3])\n",
    "\n",
    "        # intitialize the average left and right fit empty lists - these will be updated in every iteration\n",
    "        average_left_fit = []\n",
    "        average_right_fit = []\n",
    "\n",
    "        # print current video file\n",
    "        print(\"Working on video file \" + item)\n",
    "    \n",
    "        #########################################################################################\n",
    "        ################ -------- This section deals with the statusbar -------- ################\n",
    "\n",
    "        # Opens the Video file\n",
    "        # code for extracting frames starts here ...\n",
    "        video = cv2.VideoCapture(item)\n",
    "        video_clip = mpy.VideoFileClip(item)\n",
    "        frames = int(video_clip.fps * video_clip.duration)\n",
    "\n",
    "        # this section deals with printing the extraction status\n",
    "        # code to print status\n",
    "        frames_per_status_update = int(frames/100)  # update status for evey 2%\n",
    "\n",
    "        bar = progressbar.ProgressBar(maxval=100, widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "        bar.start()\n",
    "\n",
    "        #########################################################################################\n",
    "        #########################################################################################\n",
    "        # no of processed frames\n",
    "        processed_frames = 0\n",
    "        # one set of frames processed\n",
    "        processed_sets = 0\n",
    "        # number of frames that could not be processed\n",
    "        error_frame = 0\n",
    "\n",
    "        while(video.isOpened()):\n",
    "            # extract frame from the video file\n",
    "            ret, frame = video.read()\n",
    "            if(ret == True):\n",
    "\n",
    "                # run advanced lanelines detection function\n",
    "                transformed_image, binary_image, left_poly_fit, right_poly_fit = advanced_lanelines(frame)\n",
    "                \n",
    "                # We will reduce the resolution by 1/4th in order to reduce overload of GPUs capacity\n",
    "                \n",
    "                ###################### SAVE TRANSFORMED IMAGES #######################\n",
    "                trans_filepath = save_transformed_img(transformed_image, i, folder_rel_path_transformed)\n",
    "                \n",
    "                ######################### SAVE BINARY IMAGES #########################\n",
    "                bin_filepath = save_binary_img(binary_image, i, folder_rel_path_binary)\n",
    "                \n",
    "                '''\n",
    "                ####################### SAVE ORIGINAL IMAGES ########################\n",
    "                # We will reduce the resolution in order to reduce CNN capacity\n",
    "                # change resolution by adjusting fx and fy values\n",
    "                orig_image = cv2.resize(orig_image, None, fx = 0.25, fy = 0.25, interpolation = cv2.INTER_CUBIC)\n",
    "                # assign file name here ...\n",
    "                orig_file_name = folder_rel_path_orig + 'orig_img_' + str(i) + '.jpg'\n",
    "                # full absoulte path of the file\n",
    "                orig_abs_path = os.path.abspath(orig_file_name)\n",
    "                # path to write binary perspective transformed images to ...\n",
    "                mpimg.imsave(orig_file_name, orig_image)\n",
    "                '''\n",
    "            else:\n",
    "                error_frame += 1\n",
    "                break\n",
    "                \n",
    "            spamwriter = csv.writer(csvfile)\n",
    "\n",
    "            # this line writes the data to the .csv file line by line for every frame\n",
    "            spamwriter.writerow([trans_filepath] + [bin_filepath] + [left_poly_fit[0]] + [left_poly_fit[1]] + \\\n",
    "                            [left_poly_fit[2]] + [right_poly_fit[0]] + [right_poly_fit[1]] + [right_poly_fit[2]])\n",
    "            \n",
    "            # increment image sequence number\n",
    "            i += 1\n",
    "            \n",
    "            # data to be written to the .csv file\n",
    "            # 1. transformed image\n",
    "            # 2. binary transformed image\n",
    "            # 3, 4, 5. - Columns for left laneline\n",
    "            # 6, 7, 8 - Columns for right laneline\n",
    "\n",
    "            ##############################################################################\n",
    "            #################### code for printing extraction statuses ###################\n",
    "            # increment current frame\n",
    "            processed_frames = processed_frames + 1\n",
    "\n",
    "            if(processed_frames == frames_per_status_update):\n",
    "                processed_sets += 1\n",
    "                try:\n",
    "                    bar.update(processed_sets)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                processed_frames = 0\n",
    "\n",
    "                \n",
    "        bar.finish()\n",
    "            \n",
    "        print(f\"{error_frame-1} frames could not be processed!\")\n",
    "\n",
    "        # release the current video file\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        stop_time = time.time()\n",
    "        \n",
    "        print(f\"Extraction complete for file {item} ...\")\n",
    "        print(f\"{frames} images extracted from file {item} ...\\n\")\n",
    "        hours, rem = divmod(stop_time-start_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Time required = \" + \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "        # print(\"Time Required = \", \"{:.1f}\".format(stop_time-start_time), \"seconds\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # end of while loop\n",
    "\n",
    "# print the summary\n",
    "num_images = i - 1000001\n",
    "\n",
    "print(f\"{num_images} image data saved for {total_videos} video files ...\")\n",
    "print(\"Done!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
